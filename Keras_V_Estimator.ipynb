{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_V_Estimator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranish-Pantha/Tensorflow-Google-Colabs/blob/master/Keras_V_Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVwHsI9rucbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQtM_HCDI1q",
        "colab_type": "code",
        "outputId": "c840133b-d1b6-49a1-b9fd-095bdf12b22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data')\n",
        "#training data\n",
        "train_images2 = mnist.train.images\n",
        "train_labels2 = mnist.train.labels\n",
        "#test data\n",
        "test_images2 = mnist.test.images\n",
        "test_labels2 = mnist.test.labels\n",
        "#categories\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "#normalization\n",
        "train_images2 = train_images2/255.0\n",
        "test_images2 = test_images2/255.0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GRz9T2JM8E-",
        "colab_type": "text"
      },
      "source": [
        "This makes 4 sets of data: 2 for training the model and 2 for testing it.\n",
        "It also makes the classifications written in an array. \n",
        "Finally, we normalize the data by dividing all the data by 255 (greyscale images are on a scale from 0 to 255)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_0ro7xMM62Z",
        "colab_type": "code",
        "outputId": "6ff9c635-679f-4175-ce77-df0aa7a25dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(),\n",
        "     #keras.layers.InputLayer(input_shape= train_images2.shape, name=\"features\"), this layer wasn't needed\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax'),\n",
        "    ])\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(train_images2, train_labels2, epochs=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples\n",
            "Epoch 1/4\n",
            "55000/55000 [==============================] - 3s 63us/sample - loss: 1.2901 - acc: 0.6883\n",
            "Epoch 2/4\n",
            "55000/55000 [==============================] - 3s 61us/sample - loss: 0.5349 - acc: 0.8666\n",
            "Epoch 3/4\n",
            "55000/55000 [==============================] - 3s 61us/sample - loss: 0.4096 - acc: 0.8904\n",
            "Epoch 4/4\n",
            "55000/55000 [==============================] - 3s 62us/sample - loss: 0.3615 - acc: 0.8995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff736b5a828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5p5WUvkNqQF",
        "colab_type": "text"
      },
      "source": [
        "This is where we make the model. It has a layer that flattens all the data into a usable shape, a hidden layer with a relu activiation function, and an output layer that uses softmax.\n",
        "We compile the model here, which tells the model how it will back-propagate (using adam, based on the accuracy of categories).\n",
        "Finally fitting the model actually trains it using the training data, with 4 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00gxP-RM7Wt",
        "colab_type": "code",
        "outputId": "2b184a1c-8a0b-44f0-c627-46e9a6576689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images2, test_labels2)\n",
        "\n",
        "#prediction = model.predict(test_images2) doesn't need to be done\n",
        "\n",
        "print(\"Final loss: \",test_loss, \"Final accuracy: \",test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 45us/sample - loss: 0.3335 - acc: 0.9065\n",
            "Final loss:  0.33354910699129103 Final accuracy:  0.9065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFd2cY2SOhMw",
        "colab_type": "text"
      },
      "source": [
        "This is where we use our test data to see how accurate the model is and what the loss is. We see the accuracy is about 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt38G3TG7G6K",
        "colab_type": "code",
        "outputId": "68a1aee5-67e1-41b8-86d3-0d0dbecdbe9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "columns = [tf.feature_column.numeric_column(\"x\", shape=[28, 28])]\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=columns,\n",
        "    hidden_units=[256, 32],\n",
        "    optimizer=tf.train.AdamOptimizer(1e-4),\n",
        "    n_classes=10,\n",
        "    dropout=0.1,\n",
        "    model_dir=\"./tmp/mnist_model\"\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff735bc4048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50TOTSetUeCY",
        "colab_type": "text"
      },
      "source": [
        "This makes the estimator, specifying optimizer, columns, hidden units, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjvV3cPRU8P0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getinput(dataset):\n",
        "    return dataset.images, dataset.labels.astype(np.int32)\n",
        "\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": getinput(mnist.train)[0]},\n",
        "    y=getinput(mnist.train)[1],\n",
        "    num_epochs=None,\n",
        "    batch_size=50,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": getinput(mnist.test)[0]},\n",
        "    y=getinput(mnist.test)[1],\n",
        "    num_epochs=1,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnvaSyrHVP0Q",
        "colab_type": "text"
      },
      "source": [
        "These are the input functions that format the data in a way that the estimator can use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ItgXOsCVXfX",
        "colab_type": "code",
        "outputId": "cbbee0c6-bc03-412b-8888-2d7a4d8fef2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        }
      },
      "source": [
        "classifier.train(input_fn=train_input_fn, steps=1000) #more steps is usually better\n",
        "effectiveness = classifier.evaluate(input_fn=test_input_fn) [\"accuracy\"]\n",
        "print(\"Final accuracy: \",effectiveness)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./tmp/mnist_model/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into ./tmp/mnist_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 3.158885, step = 5001\n",
            "INFO:tensorflow:global_step/sec: 333.11\n",
            "INFO:tensorflow:loss = 2.3881338, step = 5101 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.026\n",
            "INFO:tensorflow:loss = 8.265196, step = 5201 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 407.827\n",
            "INFO:tensorflow:loss = 15.957972, step = 5301 (0.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.554\n",
            "INFO:tensorflow:loss = 3.6012728, step = 5401 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.858\n",
            "INFO:tensorflow:loss = 9.42451, step = 5501 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 413.613\n",
            "INFO:tensorflow:loss = 19.720074, step = 5601 (0.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 421.63\n",
            "INFO:tensorflow:loss = 11.429689, step = 5701 (0.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 415.936\n",
            "INFO:tensorflow:loss = 13.738489, step = 5801 (0.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 398.283\n",
            "INFO:tensorflow:loss = 9.617673, step = 5901 (0.251 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into ./tmp/mnist_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 6.588208.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-12-22T01:23:45Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./tmp/mnist_model/model.ckpt-6000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-12-22-01:23:46\n",
            "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.9588, average_loss = 0.13729958, global_step = 6000, loss = 17.379694\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: ./tmp/mnist_model/model.ckpt-6000\n",
            "Final accuracy:  0.9588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvEm10wQVX0U",
        "colab_type": "text"
      },
      "source": [
        "This trains the model using the training function.\n",
        "Then it evaluates the test data and prints out the accuracy, which is about 95%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hox8QP3A6Ow6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn2 = tf.estimator.inputs.numpy_input_fn(\n",
        "x={\"input_1\":getinput(mnist.train)[0] },  \n",
        "y=getinput(mnist.train)[1],\n",
        "batch_size=50,\n",
        "num_epochs=None,\n",
        "shuffle=True)\n",
        "\n",
        "test_input_fn2 = tf.estimator.inputs.numpy_input_fn(\n",
        "x={\"input_1\": getinput(mnist.test)[0]},  \n",
        "y=getinput(mnist.test)[1],\n",
        "num_epochs=1, #could have increased this, but it seemed unnecessary\n",
        "shuffle=False)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9KQAbnl3_Fq",
        "colab_type": "text"
      },
      "source": [
        "These are the new input functions because the dictionary for the converted model will be different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMZ2uvQPKvUT",
        "colab_type": "code",
        "outputId": "b9afeb3d-4e11-4341-825a-9644f33b8a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "\n",
        "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
        "    keras_model=model)\n",
        "keras_estimator.train(train_input_fn2, steps= 1000)\n",
        "efficiency2 =keras_estimator.evaluate(input_fn=test_input_fn2)[\"acc\"] #[\"accuracy\"]had trouble getting this to work until I realized it was \"acc\"\n",
        "print(\"Accuracy: \", effectiveness2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_9zst1aj\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
            "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_9zst1aj', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff736e72e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_9zst1aj/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.4333007, step = 1\n",
            "INFO:tensorflow:global_step/sec: 454.889\n",
            "INFO:tensorflow:loss = 0.44379747, step = 101 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.38\n",
            "INFO:tensorflow:loss = 0.31826964, step = 201 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.032\n",
            "INFO:tensorflow:loss = 0.2831221, step = 301 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.097\n",
            "INFO:tensorflow:loss = 0.41091356, step = 401 (0.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.478\n",
            "INFO:tensorflow:loss = 0.33651853, step = 501 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.69\n",
            "INFO:tensorflow:loss = 0.12748796, step = 601 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.638\n",
            "INFO:tensorflow:loss = 0.28824005, step = 701 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 516.591\n",
            "INFO:tensorflow:loss = 0.29309657, step = 801 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.171\n",
            "INFO:tensorflow:loss = 0.049537826, step = 901 (0.191 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_9zst1aj/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.13235775.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-12-22T01:23:49Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_9zst1aj/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-12-22-01:23:49\n",
            "INFO:tensorflow:Saving dict for global step 1000: acc = 0.9468, global_step = 1000, loss = 0.18389101\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmp_9zst1aj/model.ckpt-1000\n",
            "Accuracy:  0.9354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRO6x92HLjpp",
        "colab_type": "text"
      },
      "source": [
        "This is where the original keras model is converted into an estimator model. It is then trained and evaluated. The accuracy is about 93%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdLq6m_o9zgU",
        "colab_type": "text"
      },
      "source": [
        "The estimator api would be used for distributed environments and is able to rerun on multiple processing units.\n",
        "In keras, I had to build a model with different layers. Estimator has pre-made estimators that I could choose from. Overall, however, both are high level tensorflow apis that make creating machine learning models easier.\n",
        "For this particular dataset, the estimator model was more accurate, as seen with the first estimator model and the converted one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGHrPI58Zfwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}